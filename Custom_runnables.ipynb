{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPsFt2TZx8HCQ5Hy/IBlkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaknavadiya/Langchain-fundamentals-practice/blob/main/Custom_runnables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tuJNRCCxgYBr"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Runnable(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def invoke(input_data):\n",
        "        pass"
      ],
      "metadata": {
        "id": "WWPDBKAggaat"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLLM(Runnable):\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"Custom LLM Created\")\n",
        "\n",
        "    def invoke(self, prompt):\n",
        "        response_list = [\n",
        "            \"This is langchain runnable custom implementation\",\n",
        "            \"Ottawa is capital of Canada\"\n",
        "            \"AI is going to boom in coming years\"\n",
        "        ]\n",
        "\n",
        "        return {\"response\": random.choice(response_list)}\n"
      ],
      "metadata": {
        "id": "9u6LCXALgehI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomPromtTemplate(Runnable):\n",
        "\n",
        "    def __init__(self, template, input_variables):\n",
        "        self.template = template\n",
        "        self.input_variables = input_variables\n",
        "\n",
        "    def invoke(self, input_dict):\n",
        "        return self.template.format(**input_dict)"
      ],
      "metadata": {
        "id": "3tn-xJJHgvH4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunnableConnector(Runnable):\n",
        "\n",
        "  def __init__(self, runnable_list) :\n",
        "    self.runnable_list = runnable_list\n",
        "\n",
        "  def invoke(self, input_data):\n",
        "\n",
        "    for runnable in self.runnable_list:\n",
        "      input_data = runnable.invoke(input_data)\n",
        "\n",
        "    return input_data"
      ],
      "metadata": {
        "id": "Hx6IpoTyhIKG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = CustomLLM()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf-3Oovwgh0O",
        "outputId": "011f2957-6fac-4751-e2d7-a9510f99d520"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom LLM Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = CustomPromtTemplate(template=\"How {subject} is going to perform\", input_variables=[\"subject\"])"
      ],
      "metadata": {
        "id": "zc69JJ2XgrA6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnableConnector([template, llm])"
      ],
      "metadata": {
        "id": "TPn9BnrFhoyL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"subject\":\"AI\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1Cw-nfthry_",
        "outputId": "9f0888cb-1ec1-4728-f785-a1fc1ab6a7b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': 'Ottawa is capital of CanadaAI is going to boom in coming years'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple LLm calls using custom chain\n"
      ],
      "metadata": {
        "id": "i7LI3xAv6cWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template1 = CustomPromtTemplate(template=\"Give me top 5 news headlines of {country}\", input_variables=[\"country\"])"
      ],
      "metadata": {
        "id": "Skx9dSiE6X-6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template2 = CustomPromtTemplate(template=\"Give mesummary of this 5 news headlines - {response}\", input_variables=[\"response\"])\n"
      ],
      "metadata": {
        "id": "IHysHgZW6iFp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomStringParser(Runnable):\n",
        "\n",
        "  def __init__(self):\n",
        "    print(\"Custom String Parser Created\")\n",
        "\n",
        "  def invoke(self, input_data):\n",
        "    return input_data[\"response\"]"
      ],
      "metadata": {
        "id": "aFqc8tw68OkU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = CustomStringParser()\n",
        "chain1 = RunnableConnector([template1, llm])\n",
        "chain2 = RunnableConnector([template2, llm, parser])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeyqsKDI7XAJ",
        "outputId": "88aa5a36-bc53-4395-a1a2-eb2fbf1f25c7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom String Parser Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain = RunnableConnector([chain1, chain2])"
      ],
      "metadata": {
        "id": "qJ05WQwl7s4B"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain.invoke({\"country\":\"Canada\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2Vq1EO9U7wKR",
        "outputId": "86087c05-4948-493f-a43b-a6783d512012"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is langchain runnable custom implementation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}